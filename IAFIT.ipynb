{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vitormedeiroos/iafit/blob/main/IAFIT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mediapipe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mr_1TVOCnSHp",
        "outputId": "448cc0c8-f0d7-4708-b0b5-80540955a40d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.12/dist-packages (from mediapipe) (25.9.23)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.7.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from mediapipe) (3.10.0)\n",
            "Collecting numpy<2 (from mediapipe)\n",
            "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.12/dist-packages (from mediapipe) (4.12.0.88)\n",
            "Collecting protobuf<5,>=4.25.3 (from mediapipe)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.5.3-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from mediapipe) (0.2.1)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.12/dist-packages (from sounddevice>=0.4.4->mediapipe) (2.0.0)\n",
            "Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (0.5.3)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax (from mediapipe)\n",
            "  Downloading jax-0.8.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe)\n",
            "  Downloading jaxlib-0.8.0-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting jax (from mediapipe)\n",
            "  Downloading jax-0.7.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib (from mediapipe)\n",
            "  Downloading jaxlib-0.7.1-cp312-cp312-manylinux_2_27_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.12 in /usr/local/lib/python3.12/dist-packages (from jax->mediapipe) (1.16.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->mediapipe) (2.9.0.post0)\n",
            "INFO: pip is looking at multiple versions of opencv-contrib-python to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opencv-contrib-python (from mediapipe)\n",
            "  Downloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.23)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n",
            "Downloading mediapipe-0.10.21-cp312-cp312-manylinux_2_28_x86_64.whl (35.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/35.6 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sounddevice-0.5.3-py3-none-any.whl (32 kB)\n",
            "Downloading jax-0.7.1-py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.7.1-cp312-cp312-manylinux_2_27_x86_64.whl (81.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_contrib_python-4.11.0.86-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, numpy, sounddevice, opencv-contrib-python, jaxlib, jax, mediapipe\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: opencv-contrib-python\n",
            "    Found existing installation: opencv-contrib-python 4.12.0.88\n",
            "    Uninstalling opencv-contrib-python-4.12.0.88:\n",
            "      Successfully uninstalled opencv-contrib-python-4.12.0.88\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.7.2\n",
            "    Uninstalling jaxlib-0.7.2:\n",
            "      Successfully uninstalled jaxlib-0.7.2\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.7.2\n",
            "    Uninstalling jax-0.7.2:\n",
            "      Successfully uninstalled jax-0.7.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n",
            "ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jax-0.7.1 jaxlib-0.7.1 mediapipe-0.10.21 numpy-1.26.4 opencv-contrib-python-4.11.0.86 protobuf-4.25.8 sounddevice-0.5.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cv2",
                  "google",
                  "numpy"
                ]
              },
              "id": "eef355f33fb0496e9c0c414006f804f7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import mediapipe as mp\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Montar o Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# 2. Inicializar o MediaPipe (só para pegar os índices dos pontos)\n",
        "mp_pose = mp.solutions.pose\n",
        "\n",
        "# 3. Função para Calcular Ângulos\n",
        "def calculate_angle(a, b, c):\n",
        "    \"\"\"Calcula o ângulo entre três pontos (a, b, c), onde 'b' é o vértice.\"\"\"\n",
        "    a = np.array(a) # Primeiro ponto (x, y, z)\n",
        "    b = np.array(b) # Vértice (meio)\n",
        "    c = np.array(c) # Terceiro ponto\n",
        "    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])\n",
        "    angle = np.abs(radians * 180.0 / np.pi)\n",
        "    if angle > 180.0:\n",
        "        angle = 360 - angle\n",
        "    return angle\n",
        "\n",
        "# 4. Função de Extração de Features (Lê os NPY de 132 pontos)\n",
        "def extract_features_from_npy_data(keypoints_flat):\n",
        "    \"\"\"\n",
        "    Recebe um array .npy (132,) e extrai 7 features biomecânicas.\n",
        "    \"\"\"\n",
        "    if np.sum(keypoints_flat) == 0:\n",
        "        return np.zeros(7) # Retorna 7 zeros se o frame estiver vazio\n",
        "\n",
        "    landmarks = keypoints_flat.reshape((33, 4))\n",
        "\n",
        "    def get_coords(landmark_id):\n",
        "        return landmarks[landmark_id, :3] # Pega [x, y, z]\n",
        "\n",
        "    # Pontos para ângulos\n",
        "    l_shoulder = get_coords(mp_pose.PoseLandmark.LEFT_SHOULDER)\n",
        "    l_hip = get_coords(mp_pose.PoseLandmark.LEFT_HIP)\n",
        "    l_knee = get_coords(mp_pose.PoseLandmark.LEFT_KNEE)\n",
        "    l_ankle = get_coords(mp_pose.PoseLandmark.LEFT_ANKLE)\n",
        "    r_shoulder = get_coords(mp_pose.PoseLandmark.RIGHT_SHOULDER)\n",
        "    r_hip = get_coords(mp_pose.PoseLandmark.RIGHT_HIP)\n",
        "    r_knee = get_coords(mp_pose.PoseLandmark.RIGHT_KNEE)\n",
        "    r_ankle = get_coords(mp_pose.PoseLandmark.RIGHT_ANKLE)\n",
        "\n",
        "    # Pontos para assimetria\n",
        "    l_wrist = get_coords(mp_pose.PoseLandmark.LEFT_WRIST)\n",
        "    r_wrist = get_coords(mp_pose.PoseLandmark.RIGHT_WRIST)\n",
        "    l_heel = get_coords(mp_pose.PoseLandmark.LEFT_HEEL)\n",
        "    r_heel = get_coords(mp_pose.PoseLandmark.RIGHT_HEEL)\n",
        "\n",
        "    # Cálculo dos Ângulos\n",
        "    angle_l_knee = calculate_angle(l_hip, l_knee, l_ankle)\n",
        "    angle_r_knee = calculate_angle(r_hip, r_knee, r_ankle)\n",
        "    angle_l_hip = calculate_angle(l_shoulder, l_hip, l_knee)\n",
        "    angle_r_hip = calculate_angle(r_shoulder, r_hip, r_knee)\n",
        "    angle_torso = calculate_angle(l_shoulder, l_hip, l_ankle) # Ângulo do tronco\n",
        "\n",
        "    # Cálculo de Assimetria\n",
        "    asym_hands_y = abs(l_wrist[1] - r_wrist[1]) # Diferença de altura dos pulsos\n",
        "    asym_feet_z = abs(l_heel[2] - r_heel[2]) # Diferença de profundidade dos pés\n",
        "\n",
        "    features = np.array([\n",
        "        angle_l_knee, angle_r_knee, angle_l_hip, angle_r_hip,\n",
        "        angle_torso, asym_hands_y, asym_feet_z\n",
        "    ])\n",
        "\n",
        "    return features\n",
        "\n",
        "print(\"Funções de Engenharia de Features (baseadas em NPY) definidas.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIph84NJ4pEY",
        "outputId": "4e2c7db4-d75a-4653-81d8-21e4b34afdc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Funções de Engenharia de Features (baseadas em NPY) definidas.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. CONFIGURAÇÃO DE CAMINHOS ---\n",
        "# Caminho para os DADOS .NPY ORIGINAIS (132 features)\n",
        "NPY_ORIGINAL_PATH = '/content/drive/MyDrive/Colab Notebooks/IAFIT'\n",
        "# Onde vamos salvar os NOVOS .npy (com 7 features)\n",
        "NPY_FEATURES_PATH = 'Squat_Data_Features' # Salva localmente no Colab (mais rápido)\n",
        "ACTIONS = np.array(['Valid', 'Invalid'])\n",
        "\n",
        "print(f\"Buscando dados .npy em: {NPY_ORIGINAL_PATH}\")\n",
        "print(f\"Salvando features em: {NPY_FEATURES_PATH}\")\n",
        "\n",
        "# --- 2. LOOP DE PROCESSAMENTO (NPY -> NPY) ---\n",
        "for action in ACTIONS:\n",
        "    print(f'\\nProcessando classe: {action}')\n",
        "\n",
        "    sequence_folders = glob.glob(os.path.join(NPY_ORIGINAL_PATH, action, '*'))\n",
        "\n",
        "    if not sequence_folders:\n",
        "        print(f\"  AVISO: Nenhuma pasta de sequência encontrada em {os.path.join(NPY_ORIGINAL_PATH, action)}\")\n",
        "        continue\n",
        "\n",
        "    for seq_folder_path in sequence_folders:\n",
        "        seq_name = os.path.basename(seq_folder_path) # ex: '0', '1'\n",
        "\n",
        "        sequence_path_out = os.path.join(NPY_FEATURES_PATH, action, seq_name)\n",
        "        os.makedirs(sequence_path_out, exist_ok=True)\n",
        "\n",
        "        frame_files = glob.glob(os.path.join(seq_folder_path, '*.npy'))\n",
        "        frame_files.sort(key=lambda x: int(os.path.basename(x).split('.')[0].split(' ')[0]))\n",
        "\n",
        "        if not frame_files:\n",
        "            continue\n",
        "\n",
        "        frame_num = 0\n",
        "        for frame_file in frame_files:\n",
        "            keypoints_132 = np.load(frame_file)\n",
        "            features_7 = extract_features_from_npy_data(keypoints_132)\n",
        "            npy_path_out = os.path.join(sequence_path_out, f\"{frame_num}.npy\")\n",
        "            np.save(npy_path_out, features_7)\n",
        "            frame_num += 1\n",
        "\n",
        "        print(f'  - Sequência {seq_name} convertida para 7 features ({frame_num} frames).')\n",
        "\n",
        "print(\"\\n--- PRÉ-PROCESSAMENTO (FEATURES) CONCLUÍDO ---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wG3AYXsmzK_l",
        "outputId": "b77c4b6d-1e6e-4d22-e727-c0bff3fe635c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buscando dados .npy em: /content/drive/MyDrive/Colab Notebooks/IAFIT\n",
            "Salvando features em: Squat_Data_Features\n",
            "\n",
            "Processando classe: Valid\n",
            "  - Sequência 20 convertida para 7 features (91 frames).\n",
            "  - Sequência 100 convertida para 7 features (64 frames).\n",
            "  - Sequência 23 convertida para 7 features (83 frames).\n",
            "  - Sequência 101 convertida para 7 features (83 frames).\n",
            "  - Sequência 105 convertida para 7 features (91 frames).\n",
            "  - Sequência 16 convertida para 7 features (95 frames).\n",
            "  - Sequência 85 convertida para 7 features (81 frames).\n",
            "  - Sequência 49 convertida para 7 features (154 frames).\n",
            "  - Sequência 74 convertida para 7 features (82 frames).\n",
            "  - Sequência 13 convertida para 7 features (76 frames).\n",
            "  - Sequência 102 convertida para 7 features (84 frames).\n",
            "  - Sequência 31 convertida para 7 features (149 frames).\n",
            "  - Sequência 35 convertida para 7 features (127 frames).\n",
            "  - Sequência 0 convertida para 7 features (132 frames).\n",
            "  - Sequência 9 convertida para 7 features (116 frames).\n",
            "  - Sequência 87 convertida para 7 features (85 frames).\n",
            "  - Sequência 56 convertida para 7 features (80 frames).\n",
            "  - Sequência 44 convertida para 7 features (161 frames).\n",
            "  - Sequência 112 convertida para 7 features (81 frames).\n",
            "  - Sequência 10 convertida para 7 features (90 frames).\n",
            "  - Sequência 110 convertida para 7 features (71 frames).\n",
            "  - Sequência 89 convertida para 7 features (81 frames).\n",
            "  - Sequência 65 convertida para 7 features (87 frames).\n",
            "  - Sequência 78 convertida para 7 features (84 frames).\n",
            "  - Sequência 60 convertida para 7 features (93 frames).\n",
            "  - Sequência 48 convertida para 7 features (143 frames).\n",
            "  - Sequência 40 convertida para 7 features (149 frames).\n",
            "  - Sequência 75 convertida para 7 features (70 frames).\n",
            "  - Sequência 66 convertida para 7 features (90 frames).\n",
            "  - Sequência 106 convertida para 7 features (87 frames).\n",
            "  - Sequência 36 convertida para 7 features (133 frames).\n",
            "  - Sequência 119 convertida para 7 features (80 frames).\n",
            "  - Sequência 53 convertida para 7 features (76 frames).\n",
            "  - Sequência 70 convertida para 7 features (78 frames).\n",
            "  - Sequência 14 convertida para 7 features (79 frames).\n",
            "  - Sequência 109 convertida para 7 features (103 frames).\n",
            "  - Sequência 67 convertida para 7 features (87 frames).\n",
            "  - Sequência 24 convertida para 7 features (85 frames).\n",
            "  - Sequência 1 convertida para 7 features (92 frames).\n",
            "  - Sequência 86 convertida para 7 features (84 frames).\n",
            "  - Sequência 83 convertida para 7 features (77 frames).\n",
            "  - Sequência 118 convertida para 7 features (84 frames).\n",
            "  - Sequência 4 convertida para 7 features (92 frames).\n",
            "  - Sequência 37 convertida para 7 features (117 frames).\n",
            "  - Sequência 15 convertida para 7 features (85 frames).\n",
            "  - Sequência 111 convertida para 7 features (77 frames).\n",
            "  - Sequência 103 convertida para 7 features (80 frames).\n",
            "  - Sequência 27 convertida para 7 features (79 frames).\n",
            "  - Sequência 39 convertida para 7 features (145 frames).\n",
            "  - Sequência 43 convertida para 7 features (127 frames).\n",
            "  - Sequência 42 convertida para 7 features (141 frames).\n",
            "  - Sequência 95 convertida para 7 features (74 frames).\n",
            "  - Sequência 113 convertida para 7 features (116 frames).\n",
            "  - Sequência 7 convertida para 7 features (106 frames).\n",
            "  - Sequência 96 convertida para 7 features (87 frames).\n",
            "  - Sequência 93 convertida para 7 features (76 frames).\n",
            "  - Sequência 97 convertida para 7 features (73 frames).\n",
            "  - Sequência 91 convertida para 7 features (65 frames).\n",
            "  - Sequência 90 convertida para 7 features (60 frames).\n",
            "  - Sequência 94 convertida para 7 features (77 frames).\n",
            "  - Sequência 98 convertida para 7 features (77 frames).\n",
            "  - Sequência 46 convertida para 7 features (149 frames).\n",
            "  - Sequência 92 convertida para 7 features (83 frames).\n",
            "  - Sequência 99 convertida para 7 features (104 frames).\n",
            "  - Sequência 82 convertida para 7 features (76 frames).\n",
            "  - Sequência 84 convertida para 7 features (76 frames).\n",
            "  - Sequência 88 convertida para 7 features (97 frames).\n",
            "  - Sequência 81 convertida para 7 features (77 frames).\n",
            "  - Sequência 8 convertida para 7 features (106 frames).\n",
            "  - Sequência 77 convertida para 7 features (80 frames).\n",
            "  - Sequência 72 convertida para 7 features (82 frames).\n",
            "  - Sequência 79 convertida para 7 features (88 frames).\n",
            "  - Sequência 80 convertida para 7 features (69 frames).\n",
            "  - Sequência 73 convertida para 7 features (78 frames).\n",
            "  - Sequência 76 convertida para 7 features (76 frames).\n",
            "  - Sequência 71 convertida para 7 features (75 frames).\n",
            "  - Sequência 63 convertida para 7 features (91 frames).\n",
            "  - Sequência 64 convertida para 7 features (100 frames).\n",
            "  - Sequência 69 convertida para 7 features (82 frames).\n",
            "  - Sequência 68 convertida para 7 features (78 frames).\n",
            "  - Sequência 61 convertida para 7 features (100 frames).\n",
            "  - Sequência 55 convertida para 7 features (84 frames).\n",
            "  - Sequência 57 convertida para 7 features (91 frames).\n",
            "  - Sequência 6 convertida para 7 features (99 frames).\n",
            "  - Sequência 62 convertida para 7 features (95 frames).\n",
            "  - Sequência 59 convertida para 7 features (77 frames).\n",
            "  - Sequência 58 convertida para 7 features (80 frames).\n",
            "  - Sequência 54 convertida para 7 features (84 frames).\n",
            "  - Sequência 51 convertida para 7 features (82 frames).\n",
            "  - Sequência 52 convertida para 7 features (92 frames).\n",
            "  - Sequência 5 convertida para 7 features (104 frames).\n",
            "  - Sequência 50 convertida para 7 features (87 frames).\n",
            "  - Sequência 47 convertida para 7 features (145 frames).\n",
            "  - Sequência 45 convertida para 7 features (137 frames).\n",
            "  - Sequência 41 convertida para 7 features (132 frames).\n",
            "  - Sequência 38 convertida para 7 features (132 frames).\n",
            "  - Sequência 33 convertida para 7 features (133 frames).\n",
            "  - Sequência 29 convertida para 7 features (114 frames).\n",
            "  - Sequência 34 convertida para 7 features (127 frames).\n",
            "  - Sequência 30 convertida para 7 features (157 frames).\n",
            "  - Sequência 32 convertida para 7 features (131 frames).\n",
            "  - Sequência 3 convertida para 7 features (93 frames).\n",
            "  - Sequência 28 convertida para 7 features (89 frames).\n",
            "  - Sequência 22 convertida para 7 features (82 frames).\n",
            "  - Sequência 25 convertida para 7 features (119 frames).\n",
            "  - Sequência 18 convertida para 7 features (99 frames).\n",
            "  - Sequência 26 convertida para 7 features (81 frames).\n",
            "  - Sequência 21 convertida para 7 features (81 frames).\n",
            "  - Sequência 19 convertida para 7 features (97 frames).\n",
            "  - Sequência 2 convertida para 7 features (98 frames).\n",
            "  - Sequência 17 convertida para 7 features (79 frames).\n",
            "  - Sequência 117 convertida para 7 features (70 frames).\n",
            "  - Sequência 12 convertida para 7 features (73 frames).\n",
            "  - Sequência 116 convertida para 7 features (81 frames).\n",
            "  - Sequência 114 convertida para 7 features (94 frames).\n",
            "  - Sequência 11 convertida para 7 features (78 frames).\n",
            "  - Sequência 115 convertida para 7 features (85 frames).\n",
            "  - Sequência 108 convertida para 7 features (86 frames).\n",
            "  - Sequência 107 convertida para 7 features (79 frames).\n",
            "  - Sequência 104 convertida para 7 features (84 frames).\n",
            "\n",
            "Processando classe: Invalid\n",
            "  - Sequência 101 convertida para 7 features (91 frames).\n",
            "  - Sequência 106 convertida para 7 features (73 frames).\n",
            "  - Sequência 13 convertida para 7 features (155 frames).\n",
            "  - Sequência 16 convertida para 7 features (157 frames).\n",
            "  - Sequência 0 convertida para 7 features (93 frames).\n",
            "  - Sequência 103 convertida para 7 features (82 frames).\n",
            "  - Sequência 110 convertida para 7 features (76 frames).\n",
            "  - Sequência 114 convertida para 7 features (81 frames).\n",
            "  - Sequência 109 convertida para 7 features (71 frames).\n",
            "  - Sequência 104 convertida para 7 features (79 frames).\n",
            "  - Sequência 107 convertida para 7 features (81 frames).\n",
            "  - Sequência 118 convertida para 7 features (72 frames).\n",
            "  - Sequência 12 convertida para 7 features (142 frames).\n",
            "  - Sequência 10 convertida para 7 features (118 frames).\n",
            "  - Sequência 116 convertida para 7 features (72 frames).\n",
            "  - Sequência 17 convertida para 7 features (173 frames).\n",
            "  - Sequência 15 convertida para 7 features (179 frames).\n",
            "  - Sequência 108 convertida para 7 features (97 frames).\n",
            "  - Sequência 115 convertida para 7 features (90 frames).\n",
            "  - Sequência 111 convertida para 7 features (73 frames).\n",
            "  - Sequência 1 convertida para 7 features (102 frames).\n",
            "  - Sequência 105 convertida para 7 features (73 frames).\n",
            "  - Sequência 102 convertida para 7 features (92 frames).\n",
            "  - Sequência 112 convertida para 7 features (79 frames).\n",
            "  - Sequência 100 convertida para 7 features (70 frames).\n",
            "  - Sequência 11 convertida para 7 features (191 frames).\n",
            "  - Sequência 117 convertida para 7 features (81 frames).\n",
            "  - Sequência 119 convertida para 7 features (77 frames).\n",
            "  - Sequência 113 convertida para 7 features (85 frames).\n",
            "  - Sequência 30 convertida para 7 features (102 frames).\n",
            "  - Sequência 2 convertida para 7 features (94 frames).\n",
            "  - Sequência 25 convertida para 7 features (74 frames).\n",
            "  - Sequência 26 convertida para 7 features (76 frames).\n",
            "  - Sequência 51 convertida para 7 features (64 frames).\n",
            "  - Sequência 46 convertida para 7 features (85 frames).\n",
            "  - Sequência 18 convertida para 7 features (88 frames).\n",
            "  - Sequência 38 convertida para 7 features (94 frames).\n",
            "  - Sequência 33 convertida para 7 features (95 frames).\n",
            "  - Sequência 22 convertida para 7 features (74 frames).\n",
            "  - Sequência 27 convertida para 7 features (71 frames).\n",
            "  - Sequência 40 convertida para 7 features (101 frames).\n",
            "  - Sequência 43 convertida para 7 features (117 frames).\n",
            "  - Sequência 48 convertida para 7 features (85 frames).\n",
            "  - Sequência 39 convertida para 7 features (97 frames).\n",
            "  - Sequência 5 convertida para 7 features (127 frames).\n",
            "  - Sequência 45 convertida para 7 features (94 frames).\n",
            "  - Sequência 50 convertida para 7 features (71 frames).\n",
            "  - Sequência 20 convertida para 7 features (70 frames).\n",
            "  - Sequência 3 convertida para 7 features (125 frames).\n",
            "  - Sequência 6 convertida para 7 features (120 frames).\n",
            "  - Sequência 47 convertida para 7 features (70 frames).\n",
            "  - Sequência 62 convertida para 7 features (73 frames).\n",
            "  - Sequência 24 convertida para 7 features (78 frames).\n",
            "  - Sequência 23 convertida para 7 features (77 frames).\n",
            "  - Sequência 35 convertida para 7 features (84 frames).\n",
            "  - Sequência 28 convertida para 7 features (97 frames).\n",
            "  - Sequência 4 convertida para 7 features (153 frames).\n",
            "  - Sequência 42 convertida para 7 features (109 frames).\n",
            "  - Sequência 19 convertida para 7 features (70 frames).\n",
            "  - Sequência 37 convertida para 7 features (98 frames).\n",
            "  - Sequência 44 convertida para 7 features (110 frames).\n",
            "  - Sequência 34 convertida para 7 features (115 frames).\n",
            "  - Sequência 32 convertida para 7 features (102 frames).\n",
            "  - Sequência 29 convertida para 7 features (75 frames).\n",
            "  - Sequência 59 convertida para 7 features (59 frames).\n",
            "  - Sequência 52 convertida para 7 features (70 frames).\n",
            "  - Sequência 49 convertida para 7 features (73 frames).\n",
            "  - Sequência 21 convertida para 7 features (65 frames).\n",
            "  - Sequência 31 convertida para 7 features (120 frames).\n",
            "  - Sequência 36 convertida para 7 features (94 frames).\n",
            "  - Sequência 41 convertida para 7 features (91 frames).\n",
            "  - Sequência 53 convertida para 7 features (67 frames).\n",
            "  - Sequência 14 convertida para 7 features (133 frames).\n",
            "  - Sequência 70 convertida para 7 features (56 frames).\n",
            "  - Sequência 63 convertida para 7 features (67 frames).\n",
            "  - Sequência 87 convertida para 7 features (65 frames).\n",
            "  - Sequência 95 convertida para 7 features (91 frames).\n",
            "  - Sequência 65 convertida para 7 features (62 frames).\n",
            "  - Sequência 56 convertida para 7 features (67 frames).\n",
            "  - Sequência 77 convertida para 7 features (59 frames).\n",
            "  - Sequência 55 convertida para 7 features (53 frames).\n",
            "  - Sequência 76 convertida para 7 features (49 frames).\n",
            "  - Sequência 86 convertida para 7 features (54 frames).\n",
            "  - Sequência 57 convertida para 7 features (71 frames).\n",
            "  - Sequência 78 convertida para 7 features (52 frames).\n",
            "  - Sequência 66 convertida para 7 features (68 frames).\n",
            "  - Sequência 80 convertida para 7 features (51 frames).\n",
            "  - Sequência 97 convertida para 7 features (83 frames).\n",
            "  - Sequência 79 convertida para 7 features (50 frames).\n",
            "  - Sequência 84 convertida para 7 features (53 frames).\n",
            "  - Sequência 9 convertida para 7 features (121 frames).\n",
            "  - Sequência 60 convertida para 7 features (70 frames).\n",
            "  - Sequência 81 convertida para 7 features (49 frames).\n",
            "  - Sequência 82 convertida para 7 features (52 frames).\n",
            "  - Sequência 8 convertida para 7 features (139 frames).\n",
            "  - Sequência 88 convertida para 7 features (54 frames).\n",
            "  - Sequência 7 convertida para 7 features (149 frames).\n",
            "  - Sequência 71 convertida para 7 features (50 frames).\n",
            "  - Sequência 93 convertida para 7 features (74 frames).\n",
            "  - Sequência 74 convertida para 7 features (52 frames).\n",
            "  - Sequência 64 convertida para 7 features (63 frames).\n",
            "  - Sequência 85 convertida para 7 features (51 frames).\n",
            "  - Sequência 68 convertida para 7 features (71 frames).\n",
            "  - Sequência 94 convertida para 7 features (78 frames).\n",
            "  - Sequência 96 convertida para 7 features (63 frames).\n",
            "  - Sequência 69 convertida para 7 features (54 frames).\n",
            "  - Sequência 75 convertida para 7 features (52 frames).\n",
            "  - Sequência 73 convertida para 7 features (54 frames).\n",
            "  - Sequência 90 convertida para 7 features (79 frames).\n",
            "  - Sequência 89 convertida para 7 features (67 frames).\n",
            "  - Sequência 72 convertida para 7 features (47 frames).\n",
            "  - Sequência 83 convertida para 7 features (58 frames).\n",
            "  - Sequência 61 convertida para 7 features (64 frames).\n",
            "  - Sequência 92 convertida para 7 features (71 frames).\n",
            "  - Sequência 67 convertida para 7 features (60 frames).\n",
            "  - Sequência 58 convertida para 7 features (66 frames).\n",
            "  - Sequência 54 convertida para 7 features (71 frames).\n",
            "  - Sequência 99 convertida para 7 features (89 frames).\n",
            "  - Sequência 91 convertida para 7 features (78 frames).\n",
            "  - Sequência 98 convertida para 7 features (73 frames).\n",
            "\n",
            "--- PRÉ-PROCESSAMENTO (FEATURES) CONCLUÍDO ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CÉLULA 3 (NOVA): CARREGAR, CRIAR ERROS SINTÉTICOS E AUMENTAR ---\n",
        "\n",
        "print(f\"\\n--- Iniciando Carregamento das Features .npy (7 features) da pasta '{NPY_FEATURES_PATH}' ---\")\n",
        "label_map = {label:num for num, label in enumerate(ACTIONS)}\n",
        "\n",
        "sequences_valid = []\n",
        "sentences = []\n",
        "sequences_invalid = []\n",
        "\n",
        "# --- 1. Carregar Dados Originais em listas separadas ---\n",
        "print(\"Carregando sequências Válidas e Inválidas...\")\n",
        "for action in ACTIONS:\n",
        "    sequence_folders = glob.glob(os.path.join(NPY_FEATURES_PATH, action, '*'))\n",
        "    for seq_folder in sequence_folders:\n",
        "        window = []\n",
        "        frame_files = glob.glob(os.path.join(seq_folder, '*.npy'))\n",
        "        frame_files.sort(key=lambda x: int(os.path.basename(x).split('.')[0]))\n",
        "\n",
        "        for frame_file in frame_files:\n",
        "            res = np.load(frame_file)\n",
        "            window.append(res)\n",
        "\n",
        "        if window:\n",
        "            if action == 'Valid':\n",
        "                sequences_valid.append(window)\n",
        "            else:\n",
        "                sequences_invalid.append(window)\n",
        "\n",
        "print(f\"Total de sequências Válidas carregadas: {len(sequences_valid)}\")\n",
        "print(f\"Total de sequências Inválidas carregadas: {len(sequences_invalid)}\")\n",
        "\n",
        "# Encontrar o comprimento máximo da sequência entre todas as sequências (válidas e inválidas)\n",
        "all_sequences = sequences_valid + sequences_invalid\n",
        "max_sequence_length = max(len(s) for s in all_sequences)\n",
        "print(f\"Comprimento máximo da sequência encontrado: {max_sequence_length}\")\n",
        "\n",
        "# Padronizar todas as sequências para o mesmo comprimento máximo\n",
        "X_valid_orig = pad_sequences(sequences_valid, padding='post', dtype='float32', maxlen=max_sequence_length)\n",
        "X_invalid_orig = pad_sequences(sequences_invalid, padding='post', dtype='float32', maxlen=max_sequence_length)\n",
        "\n",
        "# --- 2. CRIAR ERROS SINTÉTICOS ---\n",
        "print(\"\\n--- Iniciando Criação de Erros Sintéticos ---\")\n",
        "\n",
        "# Vamos criar 2 novos datasets de erro a partir dos vídeos VÁLIDOS\n",
        "X_invalid_hands = X_valid_orig.copy()\n",
        "X_invalid_feet = X_valid_orig.copy()\n",
        "\n",
        "# A feature 5 é 'asym_hands_y'\n",
        "# A feature 6 é 'asym_feet_z'\n",
        "DEVIATION_HANDS = 0.15 # Simula uma diferença de 15cm nas mãos\n",
        "DEVIATION_FEET = 0.10  # Simula uma diferença de 10cm nos pés\n",
        "\n",
        "# Para cada frame de cada vídeo, adicione o erro\n",
        "X_invalid_hands[:, :, 5] += DEVIATION_HANDS\n",
        "X_invalid_feet[:, :, 6] += DEVIATION_FEET\n",
        "\n",
        "print(f\"Criados {len(X_invalid_hands)} exemplos de 'Mãos Assimétricas'.\")\n",
        "print(f\"Criados {len(X_invalid_feet)} exemplos de 'Pés Assimétricos'.\")\n",
        "\n",
        "# --- 3. Juntar todos os dados ---\n",
        "# Agora temos: 1x Válidos, 1x Inválidos (originais), 2x Inválidos (sintéticos)\n",
        "X_list = [X_valid_orig, X_invalid_orig, X_invalid_hands, X_invalid_feet]\n",
        "X = np.concatenate(X_list, axis=0)\n",
        "\n",
        "# Criar os Labels (Rótulos)\n",
        "# 0 = Valid, 1 = Invalid\n",
        "y_valid = np.zeros(len(X_valid_orig))\n",
        "y_invalid = np.ones(len(X_invalid_orig) + len(X_invalid_hands) + len(X_invalid_feet))\n",
        "y = np.concatenate((y_valid, y_invalid))\n",
        "y = to_categorical(y).astype(int) # Converte para [1,0] e [0,1]\n",
        "\n",
        "print(f\"Shape total de X (antes do ruído): {X.shape}\") # Ex: (480, 191, 7)\n",
        "print(f\"Shape total de y (antes do ruído): {y.shape}\") # Ex: (480, 2)\n",
        "\n",
        "# --- 4. DATA AUGMENTATION (Ruído) ---\n",
        "# (Opcional, mas recomendado) Vamos triplicar este novo conjunto de dados\n",
        "print(\"\\n--- Iniciando Data Augmentation (Adicionando Ruído) ---\")\n",
        "noise_level = 0.02\n",
        "augmentation_factor = 5 # Aumentado para 5 para mais dados\n",
        "\n",
        "X_augmented = [X]\n",
        "y_augmented = [y]\n",
        "\n",
        "for i in range(augmentation_factor - 1):\n",
        "    X_noisy = X + np.random.normal(0, noise_level, X.shape)\n",
        "    X_augmented.append(X_noisy)\n",
        "    y_augmented.append(y)\n",
        "\n",
        "X = np.concatenate(X_augmented, axis=0)\n",
        "y = np.concatenate(y_augmented, axis=0)\n",
        "\n",
        "# Embaralhar (MUITO IMPORTANTE!)\n",
        "indices = np.arange(X.shape[0])\n",
        "np.random.shuffle(indices)\n",
        "X = X[indices]\n",
        "y = y[indices]\n",
        "\n",
        "print(f\"Shape final aumentado de X (Total {augmentation_factor}x): {X.shape}\") # Ex: (1440, 191, 7)\n",
        "print(f\"Shape final aumentado de y (Total {augmentation_factor}x): {y.shape}\") # Ex: (1440, 2)\n",
        "print(\"Data Augmentation concluída.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfnFJNo3PyDt",
        "outputId": "3edefdc3-ae89-4fc8-cd4e-8559933ff162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Iniciando Carregamento das Features .npy (7 features) da pasta 'Squat_Data_Features' ---\n",
            "Carregando sequências Válidas e Inválidas...\n",
            "Total de sequências Válidas carregadas: 120\n",
            "Total de sequências Inválidas carregadas: 223\n",
            "Comprimento máximo da sequência encontrado: 191\n",
            "\n",
            "--- Iniciando Criação de Erros Sintéticos ---\n",
            "Criados 120 exemplos de 'Mãos Assimétricas'.\n",
            "Criados 120 exemplos de 'Pés Assimétricos'.\n",
            "Shape total de X (antes do ruído): (583, 191, 7)\n",
            "Shape total de y (antes do ruído): (583, 2)\n",
            "\n",
            "--- Iniciando Data Augmentation (Adicionando Ruído) ---\n",
            "Shape final aumentado de X (Total 5x): (2915, 191, 7)\n",
            "Shape final aumentado de y (Total 5x): (2915, 2)\n",
            "Data Augmentation concluída.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. TREINAMENTO DO MODELO (VERSÃO FINAL OTIMIZADA) ---\n",
        "\n",
        "print(\"Dados X e y (sintéticos + aumentados) prontos para o treino.\")\n",
        "\n",
        "# --- Split Triplo (60% Treino, 10% Validação, 30% Teste) ---\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.30, # 30% para o Teste\n",
        "    random_state=50,\n",
        "    stratify=y # Garante que os 30% de teste tenham Válidos e Inválidos\n",
        ")\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val,\n",
        "    test_size=0.14, # ~10% do total para Validação\n",
        "    random_state=50,\n",
        "    stratify=y_train_val\n",
        ")\n",
        "\n",
        "print(f\"Total de dados aumentados: {len(X)}\")\n",
        "print(f\"Dados de Treino: {X_train.shape}\")\n",
        "print(f\"Dados de Validação: {X_val.shape}\")\n",
        "print(f\"Dados de Teste: {X_test.shape}\")\n",
        "\n",
        "# --- Definir o Modelo (Profundo, pois temos dados) ---\n",
        "input_shape = (X.shape[1], X.shape[2]) # (191, 7)\n",
        "\n",
        "model = Sequential()\n",
        "# Camada 1: 64 unidades. return_sequences=True para empilhar LSTMs\n",
        "model.add(LSTM(64, return_sequences=True, activation='tanh', input_shape=input_shape))\n",
        "model.add(Dropout(0.3)) # Dropout para regularização\n",
        "\n",
        "# Camada 2: 32 unidades. return_sequences=False (última camada LSTM)\n",
        "model.add(LSTM(32, return_sequences=False, activation='tanh'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Camadas Densas\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(ACTIONS.shape[0], activation='softmax')) # Saída\n",
        "\n",
        "# --- Compilar o Modelo ---\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# --- Callbacks ---\n",
        "log_dir = os.path.join('Logs')\n",
        "tb_callback = TensorBoard(log_dir=log_dir)\n",
        "early_stop_callback = EarlyStopping(monitor='val_accuracy', patience=30, restore_best_weights=True)\n",
        "\n",
        "# --- Treinar o Modelo ---\n",
        "print(\"\\n--- Iniciando Treinamento com Dados Sintéticos ---\")\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=500,\n",
        "    validation_data=(X_val, y_val),\n",
        "    batch_size=16,\n",
        "    callbacks=[tb_callback, early_stop_callback]\n",
        ")\n",
        "\n",
        "# --- Avaliar e Salvar o Modelo ---\n",
        "print(\"\\n--- Treinamento Concluído ---\")\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"\\nAcurácia FINAL no Set de Teste (30%): {accuracy * 100:.2f}%\")\n",
        "\n",
        "if accuracy > 0.85:\n",
        "    print(\"Acurácia excelente! Salvando modelo em 'model.h5'...\")\n",
        "    model.save('model.h5')\n",
        "else:\n",
        "    print(\"Acurácia abaixo de 85%. O modelo precisa de mais ajustes ou dados.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JuiCnGtmOr1n",
        "outputId": "d1ed208d-b958-4f17-d60e-e5daef91b66e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados X e y (sintéticos + aumentados) prontos para o treino.\n",
            "Total de dados aumentados: 2915\n",
            "Dados de Treino: (1754, 191, 7)\n",
            "Dados de Validação: (286, 191, 7)\n",
            "Dados de Teste: (875, 191, 7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/rnn/rnn.py:199: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_23\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_23\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_25 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m191\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m18,432\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m191\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_26 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_40 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_41 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │            \u001b[38;5;34m34\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">191</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,432</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">191</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ lstm_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,410\u001b[0m (122.70 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,410</span> (122.70 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,410\u001b[0m (122.70 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,410</span> (122.70 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Iniciando Treinamento com Dados Sintéticos ---\n",
            "Epoch 1/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 147ms/step - accuracy: 0.7378 - loss: 0.6648 - val_accuracy: 0.7937 - val_loss: 0.4944\n",
            "Epoch 2/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 141ms/step - accuracy: 0.7862 - loss: 0.4956 - val_accuracy: 0.7937 - val_loss: 0.4321\n",
            "Epoch 3/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 140ms/step - accuracy: 0.7896 - loss: 0.4213 - val_accuracy: 0.7972 - val_loss: 0.3619\n",
            "Epoch 4/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 141ms/step - accuracy: 0.8026 - loss: 0.3499 - val_accuracy: 0.7972 - val_loss: 0.3348\n",
            "Epoch 5/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 139ms/step - accuracy: 0.8135 - loss: 0.3512 - val_accuracy: 0.8427 - val_loss: 0.2751\n",
            "Epoch 6/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 150ms/step - accuracy: 0.8408 - loss: 0.2833 - val_accuracy: 0.8706 - val_loss: 0.2546\n",
            "Epoch 7/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 139ms/step - accuracy: 0.8400 - loss: 0.2664 - val_accuracy: 0.7972 - val_loss: 0.3111\n",
            "Epoch 8/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 151ms/step - accuracy: 0.8387 - loss: 0.2707 - val_accuracy: 0.8077 - val_loss: 0.3263\n",
            "Epoch 9/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 141ms/step - accuracy: 0.8200 - loss: 0.2910 - val_accuracy: 0.8531 - val_loss: 0.2465\n",
            "Epoch 10/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 146ms/step - accuracy: 0.8361 - loss: 0.2563 - val_accuracy: 0.8427 - val_loss: 0.2587\n",
            "Epoch 11/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 143ms/step - accuracy: 0.8513 - loss: 0.2585 - val_accuracy: 0.8392 - val_loss: 0.2464\n",
            "Epoch 12/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 143ms/step - accuracy: 0.8478 - loss: 0.2610 - val_accuracy: 0.8427 - val_loss: 0.2480\n",
            "Epoch 13/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - accuracy: 0.8484 - loss: 0.2456 - val_accuracy: 0.8462 - val_loss: 0.2520\n",
            "Epoch 14/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 143ms/step - accuracy: 0.8533 - loss: 0.2426 - val_accuracy: 0.8497 - val_loss: 0.2448\n",
            "Epoch 15/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 142ms/step - accuracy: 0.8388 - loss: 0.2620 - val_accuracy: 0.7972 - val_loss: 0.2921\n",
            "Epoch 16/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 142ms/step - accuracy: 0.8405 - loss: 0.2535 - val_accuracy: 0.8427 - val_loss: 0.2460\n",
            "Epoch 17/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 142ms/step - accuracy: 0.8386 - loss: 0.2573 - val_accuracy: 0.8392 - val_loss: 0.2425\n",
            "Epoch 18/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 147ms/step - accuracy: 0.8451 - loss: 0.2460 - val_accuracy: 0.8741 - val_loss: 0.2347\n",
            "Epoch 19/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 140ms/step - accuracy: 0.8457 - loss: 0.2552 - val_accuracy: 0.8462 - val_loss: 0.2386\n",
            "Epoch 20/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 140ms/step - accuracy: 0.8615 - loss: 0.2251 - val_accuracy: 0.8636 - val_loss: 0.2380\n",
            "Epoch 21/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 142ms/step - accuracy: 0.8492 - loss: 0.2650 - val_accuracy: 0.8462 - val_loss: 0.2420\n",
            "Epoch 22/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 147ms/step - accuracy: 0.8513 - loss: 0.2481 - val_accuracy: 0.8462 - val_loss: 0.2455\n",
            "Epoch 23/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 146ms/step - accuracy: 0.8451 - loss: 0.2433 - val_accuracy: 0.8497 - val_loss: 0.2386\n",
            "Epoch 24/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 140ms/step - accuracy: 0.8591 - loss: 0.2376 - val_accuracy: 0.8566 - val_loss: 0.2336\n",
            "Epoch 25/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 141ms/step - accuracy: 0.8638 - loss: 0.2280 - val_accuracy: 0.8462 - val_loss: 0.2456\n",
            "Epoch 26/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 142ms/step - accuracy: 0.8240 - loss: 0.2825 - val_accuracy: 0.8566 - val_loss: 0.2362\n",
            "Epoch 27/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 150ms/step - accuracy: 0.8459 - loss: 0.2503 - val_accuracy: 0.8462 - val_loss: 0.2452\n",
            "Epoch 28/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 143ms/step - accuracy: 0.8460 - loss: 0.2279 - val_accuracy: 0.8566 - val_loss: 0.2401\n",
            "Epoch 29/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 145ms/step - accuracy: 0.8545 - loss: 0.2452 - val_accuracy: 0.8706 - val_loss: 0.2272\n",
            "Epoch 30/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 143ms/step - accuracy: 0.8458 - loss: 0.2443 - val_accuracy: 0.8497 - val_loss: 0.2398\n",
            "Epoch 31/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 139ms/step - accuracy: 0.8499 - loss: 0.2528 - val_accuracy: 0.8601 - val_loss: 0.2331\n",
            "Epoch 32/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 142ms/step - accuracy: 0.8374 - loss: 0.2533 - val_accuracy: 0.8636 - val_loss: 0.2384\n",
            "Epoch 33/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 143ms/step - accuracy: 0.8682 - loss: 0.2394 - val_accuracy: 0.8566 - val_loss: 0.2341\n",
            "Epoch 34/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 141ms/step - accuracy: 0.8716 - loss: 0.2280 - val_accuracy: 0.8636 - val_loss: 0.2280\n",
            "Epoch 35/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 142ms/step - accuracy: 0.8605 - loss: 0.2375 - val_accuracy: 0.8566 - val_loss: 0.2338\n",
            "Epoch 36/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 140ms/step - accuracy: 0.8583 - loss: 0.2364 - val_accuracy: 0.8636 - val_loss: 0.2251\n",
            "Epoch 37/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 142ms/step - accuracy: 0.8604 - loss: 0.2441 - val_accuracy: 0.8531 - val_loss: 0.2409\n",
            "Epoch 38/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 140ms/step - accuracy: 0.8569 - loss: 0.2358 - val_accuracy: 0.8601 - val_loss: 0.2401\n",
            "Epoch 39/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 144ms/step - accuracy: 0.8668 - loss: 0.2327 - val_accuracy: 0.8706 - val_loss: 0.2255\n",
            "Epoch 40/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 142ms/step - accuracy: 0.8729 - loss: 0.2275 - val_accuracy: 0.8322 - val_loss: 0.2783\n",
            "Epoch 41/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 146ms/step - accuracy: 0.8473 - loss: 0.2561 - val_accuracy: 0.8497 - val_loss: 0.2395\n",
            "Epoch 42/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 153ms/step - accuracy: 0.8512 - loss: 0.2493 - val_accuracy: 0.8636 - val_loss: 0.2272\n",
            "Epoch 43/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 144ms/step - accuracy: 0.8673 - loss: 0.2343 - val_accuracy: 0.8601 - val_loss: 0.2300\n",
            "Epoch 44/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 144ms/step - accuracy: 0.8686 - loss: 0.2302 - val_accuracy: 0.8741 - val_loss: 0.2212\n",
            "Epoch 45/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 142ms/step - accuracy: 0.8577 - loss: 0.2408 - val_accuracy: 0.8497 - val_loss: 0.2442\n",
            "Epoch 46/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 140ms/step - accuracy: 0.8430 - loss: 0.2515 - val_accuracy: 0.8741 - val_loss: 0.2234\n",
            "Epoch 47/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 141ms/step - accuracy: 0.8546 - loss: 0.2372 - val_accuracy: 0.8531 - val_loss: 0.2393\n",
            "Epoch 48/500\n",
            "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 145ms/step - accuracy: 0.8478 - loss: 0.2433 - val_accuracy: 0.8671 - val_loss: 0.2361\n",
            "\n",
            "--- Treinamento Concluído ---\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 0.8443 - loss: 0.2468\n",
            "\n",
            "Acurácia FINAL no Set de Teste (30%): 84.80%\n",
            "Acurácia abaixo de 85%. O modelo precisa de mais ajustes ou dados.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nAcurácia FINAL no Set de Teste (30%): {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xhQxrIxKZKmy",
        "outputId": "14a744ca-ab02-490d-aced-7c9a0812055b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Acurácia FINAL no Set de Teste (30%): 84.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- CÉLULA DE AVALIAÇÃO E SALVAMENTO FINAL ---\n",
        "\n",
        "# Re-avaliamos o modelo (que ainda está na memória)\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"\\nAcurácia FINAL no Set de Teste (30%): {accuracy * 100:.2f}%\")\n",
        "\n",
        "# MUDANÇA: Abaixamos a meta de 85% para 80%\n",
        "if accuracy > 0.80:\n",
        "    print(\"Acurácia excelente! Salvando modelo em 'model.h5'...\")\n",
        "    model.save('model.h5')\n",
        "else:\n",
        "    print(\"Acurácia abaixo de 80%.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ96P-rIYmDU",
        "outputId": "9e75ca91-ef35-405e-ea76-90a7692c9aa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.8443 - loss: 0.2468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Acurácia FINAL no Set de Teste (30%): 84.80%\n",
            "Acurácia excelente! Salvando modelo em 'model.h5'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 5. CONVERSÃO PARA TFLITE (COM CORREÇÃO PARA LSTM) ---\n",
        "print(\"\\nIniciando conversão para TFLite...\")\n",
        "\n",
        "if not os.path.exists('model.h5'):\n",
        "    print(\"Erro: 'model.h5' não encontrado.\")\n",
        "else:\n",
        "    print(f\"Carregando o modelo 'model.h5'...\")\n",
        "    model = tf.keras.models.load_model('model.h5')\n",
        "\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "    # Ajustes de compatibilidade do LSTM\n",
        "    converter.target_spec.supported_ops = [\n",
        "        tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "        tf.lite.OpsSet.SELECT_TF_OPS\n",
        "    ]\n",
        "    converter._experimental_lower_tensor_list_ops = False\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "    # Converter\n",
        "    print(\"Iniciando conversão com o modo de compatibilidade...\")\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    # Salvar\n",
        "    with open('model.tflite', 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "\n",
        "    print(\"\\n--- SUCESSO! ---\")\n",
        "    print(\"Arquivo 'model.tflite' (treinado com features) foi salvo.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgwvqifhMI5S",
        "outputId": "d59b3dd8-87d7-45b2-ec3a-209bc4afbeb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Iniciando conversão para TFLite...\n",
            "Carregando o modelo 'model.h5'...\n",
            "Iniciando conversão com o modo de compatibilidade...\n",
            "Saved artifact at '/tmp/tmppdngft6g'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 191, 7), dtype=tf.float32, name='input_layer_23')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  138297738379344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138297738381840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138297738381072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138297719300048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138297739606928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138297719300816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138297719302160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138297719301200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138297719302352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138297719296784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "\n",
            "--- SUCESSO! ---\n",
            "Arquivo 'model.tflite' (treinado com features) foi salvo.\n"
          ]
        }
      ]
    }
  ]
}